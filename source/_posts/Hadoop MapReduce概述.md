---
abbrlink: 42300
---
# 概述
MapReduce是一种并行编程模型，用于大规模数据集的并行运算，将复杂的、运行于大规模集群上的并行计算过程高度抽象到两个函数：Map和Reduce，极大的方便了分布式编程工作，对不会分布式并行编程的人员十分友好。

MapReduce将复杂的、运行于大规模集群上的并行计算过程高度抽象到两个函数：Map和Reduce，在MapReduce中，一个存储在分布式文件系统中的大规模数据集会被切分成许多独立的数据块，这些数据块可以被多个Map任务并行处理。需要注意的是，适合用MapReduce来处理的数据集需要满足一个前提条件：待处理的数据集可以分解成许多小的数据集，而且每一个数据集都可以完全并行地进行处理。

MapReduce的一个设计理念是“计算向数据靠拢”，而不是“数据向计算靠拢”，因此，在一个集群中，MapReduce会尽量将Map程序就近的在HDFS数据所在的节点运行，即将计算节点和存储节点放在一起运行，从而减少了节点间的数据移动。

# MapReduce工作流程
MapReduce的核心思想可以用“分而治之”来形容，即把大量的数据集拆分成多个小的数据块在多台机器上并行处理，以下是MapReduce执行的过程：

 - 使用InputFormat模块做Map前的预处理，比如验证输入的格式是否符合输入定义，然后将文件切分成逻辑上的多个InputSplit（MapReduce对文件进行处理和运算的输入单位，只是一个逻辑概念，并没有对文件做实际切割，只是记录了要处理的数据的位置和长度）。
 - 通过RecordReader根据InputSplit中的信息来处理InputSplit中的具体记录，加载数据并转换为适合Map任务读取的键值对，输入给Map任务。
 - 	Map任务根据用户自定义的映射规则，输出一系列的<key,value>作为中间结果。
- 对Map的输出进行一定的分区（Portition），排序(Sort)，合并(Combine)，归并（Merge），得到<key,value-list>形式的中间结果，以使Reduce可以并行的处理Map的结果，从无序的<key,value>到有序的<key,value-list>,这个过程称为Shuffle。
- Reduce以一系列的<key,value-list>中间结果作为输入，执行用户定义的逻辑，输出结果给OutputFormat模块。
-	OutputFormat模块验证输出目录是否已经存在及输出结果类型是否符合配置文件中的配置类型，验证通过则输出Reduce的结果到分布式文件系统。

# Shuffle过程
Shuffle是指对Map输出结果进行分区、排序、合并等处理并交给Reduce的过程，分为Map端的Shuffle过程和Reduce端的Shuffle过程。
## Map端的Shuffle过程
Map端的Shuffle过程包括四个过程：
-	输入数据和执行Map任务
Map任务接受<key,value>作为输入后，按一定的映射规则转换成一批<key，value>
-	写入缓存
每个Map任务都会被分配一个缓存，Map的输出结果首先写入缓存，在缓存中积累一定数量的Map输出结果后，在一次性批量写入磁盘，在写入缓存之前，key和value值都会被序列化成字节数组
-	溢写（分区、排序和合并）
MapReduce的缓存容量有限，当缓存中的Map结果不断增加时，需要启动溢写操作，将缓存中的内容一次性写入磁盘，并清空缓存，不能等到缓存全部沾满后才启动溢写过程，一般会设置一个溢写比例，如0.8，当缓存占用空间达到这个比例时，就启动溢写操作。
在溢写到磁盘之前，缓存中的数据需经历一下几个过程：分区、排序、合并（可选）。
MapReduce通过Partitioner接口对键值对进行分区，将Map的结果均匀的分配到Reduce任务进行并行处理，MapReduce允许用户通过重载Partitioner接口来自定义分区方式。
对于每个分区内的所有键值对，后台线程会根据key对他们进行内存排序。
排序结束后，包含一个可选的合并（Combine）操作，只有在用户定义了Combiner函数时，才会进行合并操作，将具有相同key的<key,value>的value求和，以减少键值对的数量。
-	文件归并
每次溢写操作都会在磁盘中生成一个溢写文件，溢写文件的数量会随着MapReduce任务的执行而越来越多，在Map任务全部结束之前，系统会对所有溢写文件中的数据进行归并，将具有相同key的键值对归并成一个新的键值对，生成一个大的溢写文件。
## Reduce端的Shuffle过程
相对于Map端的Shuffle过程，Reduce端的Shuffle过程更为简单，只需从Map端读取Map结果，并执行归并操作，然后输送给Reduce任务进行处理
Reduce端的Shuffle过程包括三个步骤：
-	“领取”数据
Map端的Shuffle过程结速后，Reduce任务需要把Map的输出结果“领取”（fetch）来存放到自己所在机器的本地磁盘上，在Reduce任务真正开始前，大部分时间都在从Map端“领取”属于自己处理的分区数据。
-	 归并数据
从Map端领回的数据首先被存放在Reduce任务所在机器的缓存中，当缓存被沾满时，数据会被溢写到磁盘中，在溢写过程中会进行与Map端的shuffle过程类似的排序和合并操作。
-	 把数据输入给Reduce任务
磁盘中经过多轮归并后得到若干个大文件，不会继续归并成一个新的大文件，而是直接输入给Reduce任务，以减少磁盘读写开销

